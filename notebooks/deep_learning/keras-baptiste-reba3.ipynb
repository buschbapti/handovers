{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T17:01:31.865985",
     "start_time": "2016-12-07T17:01:31.858134"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T16:42:44.113406",
     "start_time": "2016-12-07T16:42:43.781537"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=20, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "# model.add(Dense(1, activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T16:42:44.170350",
     "start_time": "2016-12-07T16:42:44.115317"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "# model.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T16:42:44.176407",
     "start_time": "2016-12-07T16:42:44.172111"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 128)           2688        dense_input_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 128)           256         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 128)           0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 256)           33024       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 256)           512         dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 256)           0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 256)           65792       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 256)           512         dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 10)            2570        batchnormalization_3[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 105354\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this if for training only. It's the name of the text file that contains both training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T16:42:44.180305",
     "start_time": "2016-12-07T16:42:44.177841"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataNameTrain= \"baptiste-reba3-train.csv\"\n",
    "dataNameTest = \"baptiste-reba3-test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T16:42:47.377092",
     "start_time": "2016-12-07T16:42:44.181716"
    }
   },
   "outputs": [],
   "source": [
    "dataTrain = np.loadtxt(dataNameTrain, delimiter=\",\", skiprows=1)\n",
    "dataTest = np.loadtxt(dataNameTest, delimiter=\",\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T16:42:47.390621",
     "start_time": "2016-12-07T16:42:47.378965"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.        , -0.16282838,  0.76110785, -0.37865804,  0.59945448,\n",
       "        -0.14792126,  0.30589173, -0.83224183, -0.92893148,  0.7219417 ,\n",
       "         0.11748402,  0.40186744,  0.21904875,  2.32952007, -0.33009103,\n",
       "        -0.55839365, -0.27316892,  0.49377564, -0.3668738 , -0.47996572,\n",
       "         0.16550142],\n",
       "       [ 8.        ,  0.03256526, -0.07450412,  0.47708814, -0.78527557,\n",
       "        -0.25193403,  0.05555838, -0.46927532, -0.44193896,  1.37965883,\n",
       "         0.53487032,  0.28550838, -1.90195344,  1.41046677, -0.18468289,\n",
       "        -0.38005845, -0.44065509,  0.2681269 , -0.28123809, -0.35075261,\n",
       "        -0.15652698],\n",
       "       [ 6.        ,  0.42963129,  0.33180792,  0.75388141,  0.76094014,\n",
       "         0.22545793,  0.75969206, -1.39389067, -0.07975607,  1.33865431,\n",
       "         0.65349093,  0.43027813,  0.67353188,  0.11422972, -0.98957083,\n",
       "        -0.70577845, -0.43705815,  0.09005189,  0.25503179, -0.35117124,\n",
       "        -0.06272062]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTrain[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show the amount of data... should be N x 19, where N >= 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T16:42:47.395091",
     "start_time": "2016-12-07T16:42:47.392132"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 21)\n",
      "(30000, 21)\n"
     ]
    }
   ],
   "source": [
    "print (dataTrain.shape)\n",
    "print (dataTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T16:42:47.404404",
     "start_time": "2016-12-07T16:42:47.396587"
    }
   },
   "outputs": [],
   "source": [
    "rawDataTrain = dataTrain[:,1:]\n",
    "rawLabelsTrain = dataTrain[:,0]\n",
    "\n",
    "rawDataTest = dataTest[:,1:]\n",
    "rawLabelsTest = dataTest[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T16:42:47.416438",
     "start_time": "2016-12-07T16:42:47.405889"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 10 # 10 output reba values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T16:42:47.636400",
     "start_time": "2016-12-07T16:42:47.417971"
    }
   },
   "outputs": [],
   "source": [
    "indices = np.arange(len(rawLabelsTrain))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "split = 0.8 # how much of the data is training. split = 0.8 means 80% train, 20% test\n",
    "splitIdx = int(round(len(rawLabelsTrain)*0.8))\n",
    "\n",
    "X_train = rawDataTrain[indices[:splitIdx]]\n",
    "y_train = rawLabelsTrain[indices[:splitIdx]]\n",
    "y_train -= 1\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "# Y_train = np.expand_dims(y_train, axis=1)\n",
    "\n",
    "X_val = rawDataTrain[indices[splitIdx:]]\n",
    "y_val = rawLabelsTrain[indices[splitIdx:]]\n",
    "y_val -= 1\n",
    "Y_val = np_utils.to_categorical(y_val, nb_classes)\n",
    "# Y_val = np.expand_dims(y_val, axis=1)\n",
    "\n",
    "X_test = rawDataTest\n",
    "y_test = rawLabelsTest\n",
    "y_test -= 1\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "# Y_test = np.expand_dims(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T14:24:51.578093",
     "start_time": "2016-12-07T14:24:51.570625"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T14:25:02.319675",
     "start_time": "2016-12-07T14:25:02.308185"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show the amount of test/training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T16:42:47.642815",
     "start_time": "2016-12-07T16:42:47.638094"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 20)\n",
      "(80000, 10)\n",
      "(20000, 20)\n",
      "(20000, 10)\n",
      "(30000, 20)\n",
      "(30000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (Y_train.shape)\n",
    "\n",
    "print (X_val.shape)\n",
    "print (Y_val.shape)\n",
    "\n",
    "print (X_test.shape)\n",
    "print (Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some hyperparameters necessary for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T16:42:47.653936",
     "start_time": "2016-12-07T16:42:47.644166"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 50 # how many training iterations\n",
    "batch_size = 64 # in each iteration, batch learning is used. This specifies how big the batch has to be\n",
    "\n",
    "# val_split = 0.2 # validation split, how much of the training data is used for validation during training - \n",
    "# this is important, because the training data might overfit (the performance getting better), \n",
    "# but the validation split would then show the overall performance going down\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This trains the network and shows a little progress bar for each epoch, \n",
    "takes about 5min on my Nvidia Quadro K5200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T16:55:18.082020",
     "start_time": "2016-12-07T16:42:47.655491"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/50\n",
      "80000/80000 [==============================] - 17s - loss: 1.6401 - acc: 0.3500 - val_loss: 1.3713 - val_acc: 0.4336\n",
      "Epoch 2/50\n",
      "80000/80000 [==============================] - 16s - loss: 1.4106 - acc: 0.4211 - val_loss: 1.2183 - val_acc: 0.4920\n",
      "Epoch 3/50\n",
      "80000/80000 [==============================] - 16s - loss: 1.3171 - acc: 0.4561 - val_loss: 1.1268 - val_acc: 0.5346\n",
      "Epoch 4/50\n",
      "80000/80000 [==============================] - 16s - loss: 1.2389 - acc: 0.4875 - val_loss: 1.0750 - val_acc: 0.5638\n",
      "Epoch 5/50\n",
      "80000/80000 [==============================] - 16s - loss: 1.1789 - acc: 0.5134 - val_loss: 0.9992 - val_acc: 0.5883\n",
      "Epoch 6/50\n",
      "80000/80000 [==============================] - 16s - loss: 1.1297 - acc: 0.5360 - val_loss: 0.9584 - val_acc: 0.6140\n",
      "Epoch 7/50\n",
      "80000/80000 [==============================] - 16s - loss: 1.0886 - acc: 0.5541 - val_loss: 0.9166 - val_acc: 0.6293\n",
      "Epoch 8/50\n",
      "80000/80000 [==============================] - 16s - loss: 1.0540 - acc: 0.5704 - val_loss: 0.8773 - val_acc: 0.6519\n",
      "Epoch 9/50\n",
      "80000/80000 [==============================] - 16s - loss: 1.0233 - acc: 0.5855 - val_loss: 0.8608 - val_acc: 0.6542\n",
      "Epoch 10/50\n",
      "80000/80000 [==============================] - 16s - loss: 1.0041 - acc: 0.5945 - val_loss: 0.8420 - val_acc: 0.6644\n",
      "Epoch 11/50\n",
      "80000/80000 [==============================] - 16s - loss: 0.9777 - acc: 0.6058 - val_loss: 0.8136 - val_acc: 0.6814\n",
      "Epoch 12/50\n",
      "80000/80000 [==============================] - 16s - loss: 0.9619 - acc: 0.6128 - val_loss: 0.8169 - val_acc: 0.6728\n",
      "Epoch 13/50\n",
      "80000/80000 [==============================] - 15s - loss: 0.9449 - acc: 0.6208 - val_loss: 0.7960 - val_acc: 0.6846\n",
      "Epoch 14/50\n",
      "80000/80000 [==============================] - 15s - loss: 0.9314 - acc: 0.6272 - val_loss: 0.7838 - val_acc: 0.6865\n",
      "Epoch 15/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.9172 - acc: 0.6336 - val_loss: 0.7599 - val_acc: 0.6990\n",
      "Epoch 16/50\n",
      "80000/80000 [==============================] - 15s - loss: 0.9074 - acc: 0.6380 - val_loss: 0.7506 - val_acc: 0.7087\n",
      "Epoch 17/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.8971 - acc: 0.6435 - val_loss: 0.7266 - val_acc: 0.7081\n",
      "Epoch 18/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.8880 - acc: 0.6453 - val_loss: 0.7236 - val_acc: 0.7159\n",
      "Epoch 19/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.8855 - acc: 0.6490 - val_loss: 0.7210 - val_acc: 0.7196\n",
      "Epoch 20/50\n",
      "80000/80000 [==============================] - 15s - loss: 0.8705 - acc: 0.6540 - val_loss: 0.7154 - val_acc: 0.7176\n",
      "Epoch 21/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.8614 - acc: 0.6577 - val_loss: 0.7006 - val_acc: 0.7254\n",
      "Epoch 22/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.8532 - acc: 0.6631 - val_loss: 0.6915 - val_acc: 0.7274\n",
      "Epoch 23/50\n",
      "80000/80000 [==============================] - 15s - loss: 0.8481 - acc: 0.6617 - val_loss: 0.6816 - val_acc: 0.7261\n",
      "Epoch 24/50\n",
      "80000/80000 [==============================] - 13s - loss: 0.8395 - acc: 0.6653 - val_loss: 0.6743 - val_acc: 0.7343\n",
      "Epoch 25/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.8326 - acc: 0.6688 - val_loss: 0.6744 - val_acc: 0.7309\n",
      "Epoch 26/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.8281 - acc: 0.6715 - val_loss: 0.6483 - val_acc: 0.7470\n",
      "Epoch 27/50\n",
      "80000/80000 [==============================] - 13s - loss: 0.8194 - acc: 0.6747 - val_loss: 0.6528 - val_acc: 0.7436\n",
      "Epoch 28/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.8143 - acc: 0.6780 - val_loss: 0.6638 - val_acc: 0.7345\n",
      "Epoch 29/50\n",
      "80000/80000 [==============================] - 15s - loss: 0.8076 - acc: 0.6797 - val_loss: 0.6627 - val_acc: 0.7359\n",
      "Epoch 30/50\n",
      "80000/80000 [==============================] - 15s - loss: 0.8017 - acc: 0.6826 - val_loss: 0.6392 - val_acc: 0.7480\n",
      "Epoch 31/50\n",
      "80000/80000 [==============================] - 15s - loss: 0.8005 - acc: 0.6830 - val_loss: 0.6469 - val_acc: 0.7452\n",
      "Epoch 32/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.7974 - acc: 0.6852 - val_loss: 0.6318 - val_acc: 0.7562\n",
      "Epoch 33/50\n",
      "80000/80000 [==============================] - 15s - loss: 0.7949 - acc: 0.6874 - val_loss: 0.6453 - val_acc: 0.7440\n",
      "Epoch 34/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.7889 - acc: 0.6868 - val_loss: 0.6265 - val_acc: 0.7515\n",
      "Epoch 35/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.7859 - acc: 0.6890 - val_loss: 0.6300 - val_acc: 0.7496\n",
      "Epoch 36/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.7872 - acc: 0.6890 - val_loss: 0.6126 - val_acc: 0.7587\n",
      "Epoch 37/50\n",
      "80000/80000 [==============================] - 13s - loss: 0.7788 - acc: 0.6930 - val_loss: 0.6140 - val_acc: 0.7584\n",
      "Epoch 38/50\n",
      "80000/80000 [==============================] - 15s - loss: 0.7742 - acc: 0.6936 - val_loss: 0.6029 - val_acc: 0.7607\n",
      "Epoch 39/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.7757 - acc: 0.6948 - val_loss: 0.5992 - val_acc: 0.7629\n",
      "Epoch 40/50\n",
      "80000/80000 [==============================] - 13s - loss: 0.7727 - acc: 0.6961 - val_loss: 0.6128 - val_acc: 0.7578\n",
      "Epoch 41/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.7677 - acc: 0.6967 - val_loss: 0.6012 - val_acc: 0.7651\n",
      "Epoch 42/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.7605 - acc: 0.6985 - val_loss: 0.5896 - val_acc: 0.7700\n",
      "Epoch 43/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.7579 - acc: 0.7022 - val_loss: 0.5776 - val_acc: 0.7743\n",
      "Epoch 44/50\n",
      "80000/80000 [==============================] - 12s - loss: 0.7556 - acc: 0.7019 - val_loss: 0.5895 - val_acc: 0.7685\n",
      "Epoch 45/50\n",
      "80000/80000 [==============================] - 15s - loss: 0.7572 - acc: 0.7046 - val_loss: 0.6008 - val_acc: 0.7641\n",
      "Epoch 46/50\n",
      "80000/80000 [==============================] - 13s - loss: 0.7480 - acc: 0.7058 - val_loss: 0.5753 - val_acc: 0.7751\n",
      "Epoch 47/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.7491 - acc: 0.7040 - val_loss: 0.5895 - val_acc: 0.7651\n",
      "Epoch 48/50\n",
      "80000/80000 [==============================] - 13s - loss: 0.7498 - acc: 0.7058 - val_loss: 0.5612 - val_acc: 0.7758\n",
      "Epoch 49/50\n",
      "80000/80000 [==============================] - 14s - loss: 0.7466 - acc: 0.7076 - val_loss: 0.5840 - val_acc: 0.7729\n",
      "Epoch 50/50\n",
      "80000/80000 [==============================] - 12s - loss: 0.7388 - acc: 0.7088 - val_loss: 0.5859 - val_acc: 0.7689\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    nb_epoch=epochs, \n",
    "    batch_size=batch_size, \n",
    "    validation_data=(X_val, Y_val)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run the model on the test data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T16:55:19.940127",
     "start_time": "2016-12-07T16:55:18.085644"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29952/30000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T16:55:19.949541",
     "start_time": "2016-12-07T16:55:19.943175"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.58908208888371782, 0.76503333333333334]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score # this gives the mean squared error over the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T16:55:20.029918",
     "start_time": "2016-12-07T16:55:19.952032"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6e6df518a476>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T16:55:20.030746",
     "start_time": "2016-12-07T15:42:43.087Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelName = \"baptiste-reba3\"\n",
    "modelVersion = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T16:55:20.031290",
     "start_time": "2016-12-07T15:42:43.089Z"
    }
   },
   "outputs": [],
   "source": [
    "modelName = \"model-\"+modelName+'-'+str(modelVersion)\n",
    "model.save(modelName+'-full.h5')\n",
    "model.save_weights(modelName+'-weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT: STARTING FROM THE NEXT CELL YOU CAN _USE_ THE MODEL (I.E. USE THE TRAINED MODEL TO DO PREDICTIONS WITHOUT MODIFYING THE MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you came here directly without executing any of the lines above (except the imports), \n",
    "then you need to execute this:\n",
    "\n",
    "This is the same as 2 cells above (but here in case you skipped it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T17:01:57.454061",
     "start_time": "2016-12-07T17:01:57.448757"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelName = \"reba3\"\n",
    "modelVersion = 2\n",
    "modelName = \"model-\"+modelName+'-'+str(modelVersion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T17:02:00.391663",
     "start_time": "2016-12-07T17:01:58.049147"
    }
   },
   "outputs": [],
   "source": [
    "# first load the model definition (and also secretly compile the model)\n",
    "model = load_model(modelName+'-full.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now just to understand the data format, \n",
    "show the first row of the test dataset (that we use here to show how predictions are done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T17:02:19.042911",
     "start_time": "2016-12-07T17:02:19.034087"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.31099815e-01,   2.76901169e-01,  -2.52226559e-02,\n",
       "         -7.26847457e-02,   1.01047846e+00,  -7.26118031e-01,\n",
       "         -2.94650834e-01,  -1.08585917e+00,   9.35178197e-01,\n",
       "         -5.88652304e-01,   6.65678763e-01,  -1.25610261e+00,\n",
       "          2.13013092e+00,  -2.52756582e+00,   1.82643932e-01,\n",
       "         -3.09919107e-01,   4.51483315e-01,   5.88298375e-01,\n",
       "         -3.72508163e-01,   4.98656458e-02],\n",
       "       [  5.39358420e-01,  -3.64856492e-01,   8.57235816e-02,\n",
       "          4.93039267e-01,   1.56382459e+00,  -9.05761018e-02,\n",
       "         -1.34786394e+00,  -1.06783212e+00,   1.40285548e+00,\n",
       "          1.17479408e+00,   1.37042940e+00,   5.64028770e-01,\n",
       "          1.12750297e+00,  -1.38838844e+00,   1.18513457e-03,\n",
       "         -4.01957439e-01,   6.23303325e-02,   6.61052743e-01,\n",
       "          4.15961789e-01,  -5.07119290e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0:2] # note: this is different from X_test[0] (the former is a matrix, the latter a vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this uses the model to predict the output for the first element in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T17:05:12.763205",
     "start_time": "2016-12-07T17:05:12.747349"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.          0.          0.01        0.01\n",
      "   0.25        0.73000002  0.        ]]\n",
      " \n",
      "REBA: 9\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([X_test[0:1]])\n",
    "print (np.around(prediction, 2))\n",
    "print (\" \")\n",
    "print (\"REBA:\",int(np.argmax(prediction))+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and this is the actual test set output (what the above output should be as close as possible to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-07T17:04:47.376788",
     "start_time": "2016-12-07T17:04:47.370298"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "print (Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
